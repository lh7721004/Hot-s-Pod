# app/service/rag/rag_service.py
import logging
import requests
from sentence_transformers import SentenceTransformer
import chromadb
from app.core.config import settings
from app.repository.rag.rag_query_repository import RagQueryRepository
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)

class RagService:
    def __init__(self, rag_query_repo: Optional[RagQueryRepository] = None):
        logger.info("ğŸ”„ Initializing RagService...")
        self.rag_query_repo = rag_query_repo
        
        # âœ… Embedding ëª¨ë¸ - ì‹±ê¸€í†¤ì—ì„œ í•œ ë²ˆë§Œ ë¡œë”©
        self.embedding_model = SentenceTransformer(settings.EMBEDDING_MODEL_NAME)
        logger.info(f"âœ… Embedding model loaded: {settings.EMBEDDING_MODEL_NAME}")
        
        # âœ… ChromaDB í´ë¼ì´ì–¸íŠ¸ - ì‹±ê¸€í†¤ì—ì„œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”
        self.chroma_client = chromadb.PersistentClient(path=settings.CHROMA_DB_PATH)
        self.collection = self.chroma_client.get_or_create_collection(
            name="hots_pod_collection",
            metadata={"hnsw:space": "cosine"}
        )
        logger.info("âœ… ChromaDB collection ready")

    def search(self, query: str, rag_query_repo: Optional[RagQueryRepository] = None) -> List[Dict[str, Any]]:
        """
        RAG ê²€ìƒ‰ (repositoryë¥¼ ì™¸ë¶€ì—ì„œ ì£¼ì… ê°€ëŠ¥)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            rag_query_repo: ì™¸ë¶€ì—ì„œ ì£¼ì…í•  repository (Noneì´ë©´ ë‚´ë¶€ repository ì‚¬ìš©)
        """
        logger.info(f"ğŸ” RAG Search: '{query}'")
        
        # âœ… Repository ì„ íƒ: ì™¸ë¶€ ì£¼ì… > ë‚´ë¶€ repository
        repo = rag_query_repo if rag_query_repo is not None else self.rag_query_repo
        
        if repo is None:
            raise ValueError("RagQueryRepository is not available")
        
        all_categories = repo.get_all_categories()
        
        found_category_id = None
        for cat in all_categories:
            if cat['category_name'] in query:
                found_category_id = cat['category_id']
                break
        
        place_keyword = None
        for keyword in settings.PLACE_KEYWORDS:
            if keyword in query:
                place_keyword = keyword
                break

        query_vector = self.embedding_model.encode(query).tolist()
        results = self.collection.query(
            query_embeddings=[query_vector],
            n_results=20
        )
        
        if not results['ids'] or not results['ids'][0]:
            logger.warning("âš ï¸ No vector search results")
            return []
            
        retrieved_pod_ids = [int(id_str) for id_str in results['ids'][0]]
        logger.info(f"ğŸ¯ Found {len(retrieved_pod_ids)} candidates")

        final_pods = repo.filter_pods(
            pod_ids=retrieved_pod_ids,
            place_keyword=place_keyword,
            category_id=found_category_id
        )
        
        logger.info(f"âœ… Final results: {len(final_pods)} pods")
        return final_pods

    def generate_answer(self, query: str, context_pods: List[Dict[str, Any]]) -> str:
        if not context_pods:
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ê´€ë ¨ëœ ì†Œëª¨ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        context_str = "ë‹¤ìŒì€ ê´€ë ¨ ì†Œëª¨ì„ì…ë‹ˆë‹¤:\n\n"
        for i, pod in enumerate(context_pods[:5], 1):
            context_str += f"[{i}ë²ˆ]\n"
            context_str += f"- ì œëª©: {pod['title']}\n"
            context_str += f"- ì¥ì†Œ: {pod['place']}\n"
            context_str += f"- ì¼ì‹œ: {pod['event_time']}\n\n"
        
        prompt = f"""ë‹¹ì‹ ì€ Hot's PODì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

[ì •ë³´]
{context_str}

[ì§ˆë¬¸]
{query}

[ë‹µë³€]
"""

        if settings.LLM_PROVIDER == 'API':
            headers = {
                "Authorization": f"Bearer {settings.LLM_API_KEY}",
                "Content-Type": "application/json"
            }
            data = {
                "model": settings.LLM_MODEL_NAME,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 300
            }
            
            try:
                response = requests.post(
                    settings.LLM_API_URL,
                    headers=headers,
                    json=data,
                    timeout=30
                )
                response.raise_for_status()
                result = response.json()
                return result['choices'][0]['message']['content'].strip()
            except Exception as e:
                logger.error(f"âŒ LLM API failed: {e}")
                return "AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        return "LLMì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."